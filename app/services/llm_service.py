# app/services/llm_service.py
"""
LLM Service - åŸºäº Gemini API çš„å‘¨æŠ¥åˆ†ææœåŠ¡
"""

import requests
import json
import logging
from typing import Dict, Any, Optional

logger = logging.getLogger(__name__)


class LLMService:
    """LLM æœåŠ¡ç±» - è°ƒç”¨ Gemini API ç”Ÿæˆå‘¨æŠ¥åˆ†æï¼ˆJSON + HTML ç‰‡æ®µï¼‰"""

    def __init__(self, api_url: str, api_key: str, model: str = "gemini-3-pro-preview-thinking"):
        """
        åˆå§‹åŒ– LLM æœåŠ¡

        Args:
            api_url: API åœ°å€
            api_key: API å¯†é’¥
            model: æ¨¡å‹åç§°
        """
        self.api_url = api_url
        self.api_key = api_key
        self.model = model

    def generate_weekly_analysis(
        self,
        report_data: Dict[str, Any],
        stream_callback=None
    ) -> Optional[Dict[str, Any]]:
        """
        ç”Ÿæˆå‘¨æŠ¥åˆ†æå†…å®¹ï¼ˆç»“æ„åŒ– JSONï¼Œä¾› Jinja2 æ¨¡æ¿æ¸²æŸ“ï¼‰

        Args:
            report_data: å‘¨æŠ¥è¾“å…¥æ•°æ®ï¼ˆç»„åˆä¿¡æ¯ã€æŒä»“ã€è¡Œæƒ…ã€æŠ€æœ¯æŒ‡æ ‡ç­‰ï¼‰
            stream_callback: æµå¼è¾“å‡ºå›è°ƒå‡½æ•°ï¼Œæ¥æ”¶æ¯ä¸ª token æ–‡æœ¬

        Returns:
            Dict åŒ…å«ï¼ˆç¤ºæ„ç»“æ„ï¼‰ï¼š
                - core_viewpoint      æ ¸å¿ƒè§‚ç‚¹ï¼ˆå¯å« HTML ç‰‡æ®µï¼‰
                - kpis                é¡¶éƒ¨ KPI æ•°æ®
                - holdings_analysis   æŒä»“æ–‡å­—åˆ†æ
                - stock_analysis      ä¸ªè‚¡åˆ†æåˆ—è¡¨
                - action_plan         è°ƒä»“å»ºè®®åˆ—è¡¨
                - risk_assessment     é£é™©è¯„ä¼°
                - sector_view         æ¿å— & é¢˜æè§†è§’
                - target_allocation   ä¸‹å‘¨ç›®æ ‡ä»“ä½ç»“æ„
        """
        try:
            system_prompt = self._build_system_prompt()
            user_prompt = self._build_user_prompt(report_data)

            response = self._call_api(system_prompt, user_prompt, stream_callback=stream_callback)

            if response:
                logger.info("âœ“ LLM å‘¨æŠ¥åˆ†æå†…å®¹ç”ŸæˆæˆåŠŸ")
                return response
            else:
                logger.error("âœ— LLM è¿”å›ç©ºç»“æœ")
                return None

        except Exception as e:
            logger.error(f"ç”Ÿæˆå‘¨æŠ¥åˆ†æå†…å®¹å¤±è´¥: {e}", exc_info=True)
            return None

    # --------------------------------------------------------------------- #
    # æç¤ºè¯ï¼šç³»ç»Ÿè§’è‰²å®šä¹‰ + JSON è¾“å‡ºç»“æ„
    # --------------------------------------------------------------------- #
    def _build_system_prompt(self) -> str:
        """æ„å»ºç³»ç»Ÿæç¤ºè¯ï¼ˆä¸»è¦çº¦æŸè¾“å‡º JSON ç»“æ„ + å…è®¸çš„ HTMLï¼Œå°½é‡ä¸é™åˆ¶å†…å®¹å‘æŒ¥ï¼‰"""
        return r"""
# Role

ä½ æ˜¯ä¸€åç†Ÿæ‚‰ A è‚¡å¸‚åœºçš„ä¸“ä¸šæŠ•èµ„é¡¾é—®å…¼å‘¨æŠ¥å†™æ‰‹ã€‚  
ä½ çš„ä»»åŠ¡ï¼šæ ¹æ®ä¼ å…¥çš„ç»„åˆæ•°æ®ï¼Œè¾“å‡ºä¸€ä¸ª **ä¸¥æ ¼çš„ JSON å¯¹è±¡**ï¼Œç”¨äºæ¸²æŸ“ä¸€ä¸ªå‘¨åº¦æŒä»“æŠ¥å‘Šé¡µé¢ã€‚

ä½ å¯ä»¥è‡ªç”±å‘æŒ¥ä½ çš„æŠ•ç ”èƒ½åŠ›å’Œè¡¨è¾¾é£æ ¼ï¼Œä½†**å¿…é¡»**éµå®ˆä¸‹é¢çš„æ ¼å¼çº¦æŸã€‚

--------------------------------
## 1. å…è®¸ä½¿ç”¨çš„ HTMLï¼ˆåªåœ¨æŒ‡å®šå­—æ®µå†…ï¼‰

éƒ¨åˆ†å­—æ®µæ˜¯â€œå¯Œæ–‡æœ¬â€ï¼Œå‰ç«¯ä¼šç”¨ `|safe` æ¸²æŸ“ï¼Œä½ å¯ä»¥åœ¨è¿™äº›å­—æ®µä¸­åµŒå…¥ç®€å• HTML æ¥å¢å¼ºè¡¨ç°åŠ›ï¼Œä½†åªå…è®¸ï¼š

- `<strong>æ–‡æœ¬</strong>`ï¼šç”¨äºå°æ ‡é¢˜ã€å…³é”®ç»“è®ºã€æ“ä½œåŠ¨è¯ç­‰é€»è¾‘é”šç‚¹ï¼›
- `<span class="highlight-phrase">æ–‡æœ¬</span>`ï¼šç”¨äºå¼ºè°ƒç»„åˆå±‚é¢çš„é‡è¦åˆ¤æ–­ï¼›
- `<span class="text-up">+3.5%</span>` / `<span class="text-down">-4.2%</span>`ï¼šç”¨äºæ–‡å­—é‡Œçš„æ¶¨è·Œæ–¹å‘ï¼›
- `<p>æ®µè½å†…å®¹</p>`ï¼šä¸€ä¸ªè‡ªç„¶æ®µä¸€ä¸ª `<p>`ï¼›
- `<ul class="data-list"><li>æ¡ç›®</li></ul>`ï¼šå½“ä½ éœ€è¦åˆ—å‡ºå…³é”®è¦ç‚¹æ—¶ä½¿ç”¨ã€‚

**ç¦æ­¢** ä½¿ç”¨å…¶å®ƒæ ‡ç­¾ï¼ˆä¾‹å¦‚ table/div/h1/script/style ç­‰ï¼‰ï¼Œä¹Ÿä¸è¦è¾“å‡ºä»»ä½• CSS/JSã€‚

å…è®¸ HTML çš„å­—æ®µä¼šåœ¨ä¸‹é¢ JSON ç»“æ„è¯´æ˜é‡Œæ˜ç¡®æ ‡å‡ºæ¥ã€‚

--------------------------------
## 2. è¾“å‡º JSON ç»“æ„ï¼ˆå¿…é¡»å®Œå…¨åŒ¹é…ï¼‰

ä½ å¿…é¡»è¾“å‡ºä¸€ä¸ª JSON å¯¹è±¡ï¼Œç»“æ„å¦‚ä¸‹ï¼ˆç¤ºä¾‹å€¼ä»…ç”¨äºè¯´æ˜ï¼Œå®é™…å†…å®¹è¯·ä½ è‡ªå·±åˆ†æç”Ÿæˆï¼‰ï¼š

{
  "core_viewpoint": "å­—ç¬¦ä¸²ï¼Œ80-140 å­—ï¼Œå…è®¸ HTMLï¼Œç”¨æ¥åœ¨å¼€å¤´ä¸€æ®µè¯é‡Œç‚¹æ˜æœ¬å‘¨ç»„åˆçš„æ ¸å¿ƒçŸ›ç›¾ä¸ä¸»çº¿ã€‚",

  "kpis": {
    "weekly_return": 0.0,
    "benchmark_return": 0.0,
    "ytd_return": 0.0,
    "position_ratio": 0.0,
    "action_count": 0,
    "ytd_comment": "å­—ç¬¦ä¸²ï¼Œç®€çŸ­ç‚¹è¯„ä»Šå¹´ä»¥æ¥è¡¨ç°ã€‚",
    "position_comment": "å­—ç¬¦ä¸²ï¼Œå¯¹å½“å‰ä»“ä½æ°´å¹³çš„ç‚¹è¯„ã€‚",
    "action_summary": "å­—ç¬¦ä¸²ï¼Œå¯¹æœ¬å‘¨è°ƒä»“é‡ç‚¹çš„æ‘˜è¦ã€‚"
  },

  "section_subtitles": {
    "overview": "å­—ç¬¦ä¸²ï¼Œæ¦‚æ‹¬â€œæœ¬å‘¨ç»„åˆæ€»è§ˆâ€çš„ä¸€å¥è¯å°æ ‡é¢˜ã€‚",
    "holdings": "å­—ç¬¦ä¸²ï¼Œæ¦‚æ‹¬â€œæŒä»“ç›ˆäºåˆ†æâ€æƒ³è¡¨è¾¾çš„é‡ç‚¹ã€‚",
    "stock": "å­—ç¬¦ä¸²ï¼Œæ¦‚æ‹¬â€œä¸ªè‚¡ä¸ ETF åˆ†æâ€çš„è§’åº¦ï¼Œä¾‹å¦‚æ›´åæŠ€æœ¯/é¢˜æ/è½®åŠ¨ã€‚",
    "action": "å­—ç¬¦ä¸²ï¼Œæ¦‚æ‹¬â€œæœ¬å‘¨æ“ä½œè®¡åˆ’â€çš„é£æ ¼ï¼ˆå¦‚åé˜²å¾¡ã€åä¼˜åŒ–ç»“æ„ç­‰ï¼‰ã€‚",
    "risk": "å­—ç¬¦ä¸²ï¼Œæ¦‚æ‹¬é£é™©ä¸ä¼˜åŒ–éƒ¨åˆ†çš„ä¸»åŸºè°ƒã€‚",
    "sector": "å­—ç¬¦ä¸²ï¼Œæ¦‚æ‹¬æ¿å—å’Œé¢˜æè§†è§’çš„æ ¸å¿ƒè§‚ç‚¹ã€‚"
  },

  "holdings_analysis": {
    "summary": "å­—ç¬¦ä¸²ï¼Œ100-200 å­—ï¼Œå¯¹æŒä»“ç›ˆäºç»“æ„çš„æ•´ä½“ç‚¹è¯„ï¼Œå…è®¸ HTMLã€‚",
    "highlights": [
      "å­—ç¬¦ä¸²ï¼Œè¦ç‚¹ 1ï¼Œå…è®¸ HTMLã€‚",
      "å­—ç¬¦ä¸²ï¼Œè¦ç‚¹ 2ï¼Œå…è®¸ HTMLã€‚",
      "å­—ç¬¦ä¸²ï¼Œè¦ç‚¹ 3ï¼Œå…è®¸ HTMLã€‚"
    ]
  },

  "stock_analysis": [
    {
      "stock_code": "600519.SH",
      "stock_name": "è´µå·èŒ…å°",
      "stock_role": "æ ¸å¿ƒæŒä»“/å«æ˜ŸæŒä»“/é…ç½®ç±»/è§‚å¯Ÿä»“ ç­‰è‡ªç”±æè¿°",
      "status": "è¶…å–åå¼¹/æ¨ªç›˜éœ‡è¡/è¶‹åŠ¿ç ´ä½/å¤šå¤´è¶‹åŠ¿/å›è°ƒé¢„è­¦ ç­‰ä½ è®¤ä¸ºåˆé€‚çš„æ ‡ç­¾",
      "status_class": "positive/negative/warning/neutral",
      "sentiment_class": "bull/bear/neutral",

      "technical": "æŠ€æœ¯é¢åˆ†æï¼Œ50-120 å­—ï¼Œå…è®¸ HTMLï¼ˆä¾‹å¦‚ä»¥ <strong>æŠ€æœ¯é¢ï¼š</strong> å¼€å¤´ï¼‰ã€‚",
      "fundamental": "åŸºæœ¬é¢åˆ†æï¼Œ50-120 å­—ï¼Œå…è®¸ HTMLã€‚",
      "theme": "é¢˜æä¸é£æ ¼é€»è¾‘ï¼Œ50-120 å­—ï¼Œå…è®¸ HTMLï¼Œæ³¨æ„ç¬¦åˆ A è‚¡è¯è¯­ï¼ˆä¸»çº¿/è½®åŠ¨/èµ„é‡‘é£æ ¼ç­‰ï¼‰ã€‚",
      "risk": "é£é™©ç‚¹ï¼Œ30-80 å­—ï¼Œå…è®¸ HTMLã€‚",
      "suggestion": "æ“ä½œå»ºè®®ï¼Œ50-120 å­—ï¼Œå…è®¸ HTMLï¼ŒåŒ…å«æ‰§è¡Œæ€è·¯ï¼ˆå¦‚åŒºé—´ã€åˆ†æ‰¹ï¼‰ã€ä»“ä½æ€è·¯ç­‰ã€‚"
    }
  ],

  "action_plan": [
    {
      "stock_code": "600519.SH",
      "stock_name": "è´µå·èŒ…å°",
      "action": "é€¢é«˜å‡ä»“/åå¼¹å‡ä»“/é€æ­¥æ¸…ä»“/ç»§ç»­æŒæœ‰/é€¢ä½åŠ ä»“ ç­‰ç®€æ´åŠ¨è¯çŸ­è¯­",
      "action_class": "reduce/clear/add/hold",
      "price_range": "ä¾‹å¦‚ \"1460â€“1480 å…ƒ\" æˆ– \"+1% æ¶¨å¹…å†…æ‹©æœº\"",
      "current_position_pct": 45.0,
      "target_position_pct": 40.0,
      "plan": "æ‰§è¡Œè®¡åˆ’è¯´æ˜ï¼Œä¾‹å¦‚ â€œè§¦åŠåŒºé—´ä¸Šæ²¿åˆ†ä¸¤æ¬¡å„å‡ 2.5%â€ã€‚",
      "reason": "ä¸€å¥è¯é€»è¾‘æ‘˜è¦ï¼Œè¯´æ˜ä¸ºä»€ä¹ˆè¿™æ ·æ“ä½œã€‚"
    }
  ],

  "risk_assessment": {
    "level": "åä½/ä¸­ç­‰/ä¸­ç­‰åé«˜/åé«˜ ç­‰è‡ªç„¶ä¸­æ–‡æè¿°",
    "level_score": 65,
    "current_risks": [
      "å½“å‰é£é™©ç‚¹ 1ï¼Œå…è®¸ HTMLã€‚",
      "å½“å‰é£é™©ç‚¹ 2ï¼Œå…è®¸ HTMLã€‚",
      "å½“å‰é£é™©ç‚¹ 3ï¼Œå…è®¸ HTMLã€‚"
    ],
    "optimization_suggestions": [
      "ä¼˜åŒ–å»ºè®® 1ï¼Œå…è®¸ HTMLã€‚",
      "ä¼˜åŒ–å»ºè®® 2ï¼Œå…è®¸ HTMLã€‚",
      "ä¼˜åŒ–å»ºè®® 3ï¼Œå…è®¸ HTMLã€‚"
    ]
  },

  "sector_view": {
    "summary": "æ¿å— & é¢˜æç»¼åˆè§†è§’çš„å®Œæ•´æ®µè½ï¼Œå…è®¸ HTMLã€‚",
    "main_theme": "ä¸€å¥è¯è¯´æ˜ä½ çœ¼ä¸­å½“å‰å¸‚åœºèµ„é‡‘ä¸»çº¿ï¼ˆä¾‹å¦‚ â€œç§‘æŠ€æˆé•¿ï¼ˆç®—åŠ›/åŠå¯¼ä½“ï¼‰ã€é«˜è‚¡æ¯çº¢åˆ©â€ï¼‰ã€‚",
    "consumer_position": "ä¸€å¥è¯è¯´æ˜æ¶ˆè´¹æ¿å—åœ¨å½“å‰ç»“æ„ä¸­çš„ä½ç½®ã€‚",
    "portfolio_position": "ä¸€å¥è¯è¯´æ˜å½“å‰ç»„åˆåœ¨é£æ ¼/èŠ‚å¥ä¸­çš„ä½ç½®ã€‚",
    "adjustment_direction": "ä¸€å¥è¯è¯´æ˜æœªæ¥ä¸€ä¸¤å‘¨è°ƒä»“æ–¹å‘ã€‚"
  },

  "target_allocation": {
    "consumer": {
      "percent": 55,
      "label": "æ¶ˆè´¹ç›¸å…³ï¼ˆä½ å¯ä»¥è‡ªç”±å‘½åï¼Œä¾‹å¦‚â€œæ¶ˆè´¹ä¿®å¤â€ï¼‰"
    },
    "tech_growth": {
      "percent": 20,
      "label": "ç§‘æŠ€æˆé•¿ï¼ˆä¾‹å¦‚â€œç§‘æŠ€æˆé•¿/ç®—åŠ›ç›¸å…³â€ï¼‰"
    },
    "dividend": {
      "percent": 15,
      "label": "é«˜è‚¡æ¯/ä»·å€¼ï¼ˆä¾‹å¦‚â€œé«˜è‚¡æ¯ç¨³å¥èµ„äº§â€ï¼‰"
    },
    "cash": {
      "percent": 10,
      "label": "ç°é‡‘/è´§åŸºï¼ˆä¾‹å¦‚â€œç°é‡‘ç¼“å†²â€ï¼‰"
    }
  }
}

--------------------------------
## 3. ç±»å‹ & çº¦æŸæ±‡æ€»ï¼ˆéå¸¸é‡è¦ï¼‰

1. **å¿…é¡»è¾“å‡ºä¸¥æ ¼ JSON**ï¼š
   - æœ€å¤–å±‚æ˜¯ä¸€ä¸ª `{}` å¯¹è±¡ï¼›
   - ä¸å…è®¸å‡ºç°ä»»ä½•è§£é‡Šæ–‡å­—ã€æ³¨é‡Šã€é¢å¤–å­—æ®µã€‚

2. æ•°å€¼å­—æ®µå¿…é¡»æ˜¯è£¸æ•°å­—ï¼š
   - `weekly_return`, `benchmark_return`, `ytd_return`, `position_ratio`, `action_count`,
     `current_position_pct`, `target_position_pct`, `level_score`,
     ä»¥åŠ `target_allocation` ä¸­çš„ `percent`ï¼›
   - ä¸è¦åœ¨æ•°å€¼å­—æ®µé‡ŒåŠ  `%` æˆ–ä»»ä½•å•ä½ï¼Œä¹Ÿä¸è¦åµŒå…¥ HTMLã€‚

3. åªæœ‰è¿™äº›å­—æ®µå¯ä»¥åŒ…å« HTMLï¼š
   - `core_viewpoint`
   - `holdings_analysis.summary`
   - `holdings_analysis.highlights[*]`
   - `stock_analysis[*].technical`
   - `stock_analysis[*].fundamental`
   - `stock_analysis[*].theme`
   - `stock_analysis[*].risk`
   - `stock_analysis[*].suggestion`
   - `risk_assessment.current_risks[*]`
   - `risk_assessment.optimization_suggestions[*]`
   - `sector_view.summary`

4. æšä¸¾å€¼çº¦æŸï¼š
   - `status_class` âˆˆ {`positive`, `negative`, `warning`, `neutral`};
   - `sentiment_class` âˆˆ {`bull`, `bear`, `neutral`};
   - `action_class` âˆˆ {`reduce`, `clear`, `add`, `hold`}ã€‚

5. å†…å®¹é£æ ¼ï¼š
   - ä½ å¯ä»¥è‡ªç”±ä½¿ç”¨ A è‚¡å¸¸è§è¡¨è¾¾ï¼ˆä¸»çº¿ã€æƒ…ç»ªã€è½®åŠ¨ã€è¶…è·Œåå¼¹ç­‰ï¼‰ï¼›
   - è¡¨è¾¾å¯ä»¥æœ‰è‡ªå·±çš„é£æ ¼ï¼Œä½†å°½é‡**ç®€æ´ã€ä¿¡æ¯å¯†åº¦é«˜**ï¼Œé¿å…ç©ºæ´è¯­å¥ã€‚

è¯·æ ¹æ®æˆ‘ç¨åæä¾›çš„ç»„åˆæ•°æ®ï¼Œç›´æ¥è¾“å‡ºä¸€ä¸ªæ»¡è¶³ä¸Šè¿°ç»“æ„ä¸çº¦æŸçš„ JSON å¯¹è±¡ã€‚
"""

    def _build_user_prompt(self, report_data: Dict[str, Any]) -> str:
        """æ„å»ºç”¨æˆ·æç¤ºè¯ï¼šæŠŠç»„åˆ/æŒä»“/è¡Œæƒ…æ•°æ®æ‰“åŒ…ç»™æ¨¡å‹ï¼Œå°½é‡å°‘å¹²é¢„å†…å®¹ï¼Œä»…æè¿°ä¸Šä¸‹æ–‡"""

        portfolio = report_data.get("portfolio", {})
        metrics = report_data.get("metrics", {})
        holdings = report_data.get("holdings", [])
        period = report_data.get("period", "")
        benchmark_name = report_data.get("benchmark_name", "æ²ªæ·±300")
        benchmark_return = report_data.get("benchmark_return", 0.0)

        holdings_summary = []
        for h in holdings:
            indicators = h.get("indicators", {})
            holdings_summary.append(
                {
                    "è‚¡ç¥¨ä»£ç ": h.get("stock_code"),
                    "è‚¡ç¥¨åç§°": h.get("stock_name"),
                    "å½“å‰ä»·æ ¼": f"{h.get('current_price', 0.0):.2f}",
                    "æˆæœ¬ä»·": f"{h.get('cost_price', 0.0):.2f}",
                    "æŒä»“æ•°é‡": h.get("quantity", 0),
                    "å¸‚å€¼": f"{h.get('market_value', 0.0):.2f}",
                    "ç›ˆäº": f"{h.get('profit_loss', 0.0):+,.2f}",
                    "ç›ˆäºæ¯”ä¾‹": f"{h.get('profit_loss_pct', 0.0):+.2f}%",
                    "ä»“ä½å æ¯”": f"{h.get('position_ratio', 0.0):.1f}%",
                    "æŠ€æœ¯æŒ‡æ ‡": indicators
                }
            )

        total_assets = metrics.get("total_market_value", 0.0) + metrics.get("cash", 0.0)

        prompt = f"""
ä¸‹é¢æ˜¯ä¸€ä¸ªè‚¡ç¥¨ç»„åˆåœ¨æœ¬ç»Ÿè®¡å‘¨æœŸå†…çš„æ•°æ®å¿«ç…§ï¼Œè¯·ä½ åŸºäºè¿™äº›æ•°æ®ï¼Œè¾“å‡ºä¸€ä¸ªç¬¦åˆç³»ç»Ÿæç¤ºä¸­ JSON ç»“æ„çš„åˆ†æç»“æœã€‚

ã€ç»Ÿè®¡å‘¨æœŸã€‘
{period}

ã€ç»„åˆä¿¡æ¯ã€‘
- ç»„åˆåç§°ï¼š{portfolio.get('name', 'æœªå‘½åç»„åˆ')}
- æ€»èµ„äº§ï¼šÂ¥{total_assets:,.2f}
- æŒä»“å¸‚å€¼ï¼šÂ¥{metrics.get('total_market_value', 0.0):,.2f}
- ç°é‡‘ï¼šÂ¥{metrics.get('cash', 0.0):,.2f}
- å½“å‰æ•´ä½“ä»“ä½ï¼š{metrics.get('position_ratio', 0.0):.1f}%

ã€æ•´ä½“ç›ˆäºã€‹
- æ€»ç›ˆäºï¼šÂ¥{metrics.get('total_profit_loss', 0.0):+,.2f}
- æ€»ä½“æ”¶ç›Šç‡ï¼š{metrics.get('total_return_pct', 0.0):+.2f}%
- æœ¬å‘¨ç»„åˆæ”¶ç›Šç‡ï¼š{metrics.get('weekly_return', 0.0):+.2f}%
- åŸºå‡†ï¼ˆ{benchmark_name}ï¼‰æœ¬å‘¨æ”¶ç›Šç‡ï¼š{benchmark_return:+.2f}%

ã€æŒä»“æ˜ç»†åˆ—è¡¨ã€‘ï¼ˆå…± {len(holdings)} åªï¼‰
ä»¥ä¸‹ä¸ºæ¯åªæŒä»“çš„ç®€è¦æ•°æ®ä¸æŠ€æœ¯æŒ‡æ ‡ï¼ˆJSON æ•°ç»„ï¼‰ï¼š
{json.dumps(holdings_summary, ensure_ascii=False, indent=2)}

è¯·åŸºäºè¿™äº›æ•°æ®è¿›è¡Œä½ è‡ªå·±çš„ä¸“ä¸šåˆ†æå’Œåˆ¤æ–­ï¼Œè‡ªç”±å‘æŒ¥å†…å®¹ï¼Œ
ä½†æœ€ç»ˆè¾“å‡ºå¿…é¡»æ˜¯ä¸€ä¸ª**ä¸¥æ ¼ç¬¦åˆç³»ç»Ÿæç¤ºä¸­å®šä¹‰ç»“æ„çš„ JSON å¯¹è±¡**ã€‚ä¸è¦è¾“å‡ºä»»ä½•å¤šä½™è¯´æ˜æ–‡å­—ã€‚
"""

        return prompt


    # --------------------------------------------------------------------- #
    # è°ƒç”¨ APIï¼ˆæµå¼è¾“å‡º + JSON æå–ï¼‰
    # --------------------------------------------------------------------- #
    def _call_api(
        self,
        system_prompt: str,
        user_prompt: str,
        max_retries: int = 3,
        stream_callback=None
    ) -> Optional[Dict[str, Any]]:
        """
        è°ƒç”¨ Gemini APIï¼ˆæµå¼è¾“å‡ºï¼Œå¸¦é‡è¯•æœºåˆ¶ï¼‰

        Args:
            system_prompt: ç³»ç»Ÿæç¤ºè¯
            user_prompt: ç”¨æˆ·æç¤ºè¯
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            stream_callback: æµå¼è¾“å‡ºå›è°ƒå‡½æ•°

        Returns:
            è§£æåçš„ JSON å“åº”ï¼ˆå­—å…¸ï¼‰
        """
        import time
        import re

        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
        }

        payload = {
            "model": self.model,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
            "stream": True,
            "max_tokens": 50000,
            "temperature": 0.6,
            "top_p": 0.9,
            "top_k": 40,
            "frequency_penalty": 0.1,
            "response_format": {"type": "json_object"},
        }

        for attempt in range(max_retries):
            try:
                if attempt > 0:
                    wait_time = 2 ** attempt
                    logger.info(f"â³ ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    time.sleep(wait_time)

                logger.info(f"ğŸ¤– è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆå‘¨æŠ¥åˆ†æ... (å°è¯• {attempt + 1}/{max_retries})")

                response = requests.post(
                    self.api_url,
                    headers=headers,
                    json=payload,
                    stream=True,
                    timeout=300,
                )
                response.raise_for_status()

                full_content = ""
                last_log_length = 0

                for line in response.iter_lines():
                    if not line:
                        continue

                    line = line.decode("utf-8")

                    if not line.startswith("data: "):
                        continue

                    data_str = line[6:]

                    if data_str.strip() == "[DONE]":
                        logger.info("âœ“ æµå¼è¾“å‡ºå®Œæˆ")
                        break

                    try:
                        data = json.loads(data_str)
                        delta = data.get("choices", [{}])[0].get("delta", {})
                        content_chunk = delta.get("content", "")

                        if content_chunk:
                            full_content += content_chunk

                            if stream_callback:
                                stream_callback(content_chunk, len(full_content))

                            if len(full_content) - last_log_length >= 200:
                                logger.info(f"ğŸ“ å¤§æ¨¡å‹å·²ç”Ÿæˆçº¦ {len(full_content)} å­—...")
                                last_log_length = len(full_content)

                    except json.JSONDecodeError:
                        continue

                logger.info(f"âœ“ å¤§æ¨¡å‹è¾“å‡ºç»“æŸï¼Œæ€»é•¿åº¦ {len(full_content)} å­—")

                if not full_content:
                    logger.error("âœ— API è¿”å›å†…å®¹ä¸ºç©º")
                    return None

                original_content = full_content

                # 1. è¿‡æ»¤ <think> æ€è€ƒå†…å®¹
                if "<think>" in full_content:
                    think_end = full_content.find("</think>")
                    if think_end != -1:
                        full_content = full_content[think_end + len("</think>") :].strip()
                        logger.info(f"âœ“ å·²å‰¥ç¦»æ€è€ƒå†…å®¹ï¼Œå‰©ä½™ {len(full_content)} å­—")

                # 2. è‹¥åŒ…åœ¨ ```json ä»£ç å—ä¸­ï¼Œå…ˆæˆªå–
                if "```json" in full_content:
                    start = full_content.find("```json") + len("```json")
                    end = full_content.find("```", start)
                    if end != -1:
                        full_content = full_content[start:end].strip()
                        logger.info("âœ“ ä» ```json ä»£ç å—ä¸­æå–å†…å®¹")
                elif "```" in full_content:
                    start = full_content.find("```") + len("```")
                    end = full_content.find("```", start)
                    if end != -1:
                        full_content = full_content[start:end].strip()
                        logger.info("âœ“ ä» ``` ä»£ç å—ä¸­æå–å†…å®¹")

                # 3. å¦‚æœå‰é¢æœ‰å¤šä½™æ–‡å­—ï¼Œå°è¯•æ‰¾åˆ°ç¬¬ä¸€ä¸ª JSON èµ·å§‹ä½ç½®
                if "{" in full_content and not full_content.lstrip().startswith("{"):
                    json_start = full_content.find("{")
                    full_content = full_content[json_start:]
                    logger.info("âœ“ å·²æˆªæ–­åˆ°ç¬¬ä¸€ä¸ª '{{' å¼€å§‹çš„ä½ç½®")

                # 4. å…ˆå°è¯•ç›´æ¥è§£æ
                try:
                    parsed = json.loads(full_content)
                    logger.info("âœ“ ç›´æ¥è§£æ JSON æˆåŠŸ")
                    return parsed
                except json.JSONDecodeError:
                    logger.warning("âš ï¸ ç›´æ¥è§£æå¤±è´¥ï¼Œå°è¯•ç”¨æ­£åˆ™æå–æœ€å¤–å±‚ JSON å¯¹è±¡...")

                    json_pattern = r"\{(?:[^{}]|(?:\{[^{}]*\}))*\}"
                    matches = re.findall(json_pattern, full_content, re.DOTALL)

                    for i, match in enumerate(matches):
                        try:
                            parsed = json.loads(match)
                            if isinstance(parsed, dict) and (
                                "core_viewpoint" in parsed or "stock_analysis" in parsed
                            ):
                                logger.info(f"âœ“ ç¬¬ {i+1}/{len(matches)} ä¸ªåŒ¹é…æˆåŠŸè§£æ JSON")
                                return parsed
                        except json.JSONDecodeError:
                            continue

                    logger.error("âœ— æ— æ³•ä»è¿”å›å†…å®¹ä¸­è§£æå‡ºåˆæ³• JSON")
                    logger.error(f"å¤„ç†åå†…å®¹å‰ 500 å­—ï¼š{full_content[:500]}...")

                    try:
                        with open("llm_error_output.txt", "w", encoding="utf-8") as f:
                            f.write(original_content)
                        logger.error("åŸå§‹å†…å®¹å·²ä¿å­˜åˆ° llm_error_output.txt")
                    except Exception:
                        pass

                    return None

            except requests.exceptions.HTTPError as e:
                status = e.response.status_code if e.response is not None else None
                if status in [429, 500, 502, 503, 504]:
                    logger.warning(f"âš ï¸ API HTTP é”™è¯¯ {status}ï¼Œå°†é‡è¯•...")
                    if attempt == max_retries - 1:
                        logger.error("âŒ å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œæ”¾å¼ƒè¯·æ±‚")
                        return None
                    continue
                else:
                    logger.error(f"API HTTP é”™è¯¯: {e}")
                    return None
            except requests.exceptions.RequestException as e:
                logger.error(f"API è¯·æ±‚å¼‚å¸¸: {e}")
                if attempt == max_retries - 1:
                    return None
                continue
            except Exception as e:
                logger.error(f"å¤„ç†æµå¼è¾“å‡ºæ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}", exc_info=True)
                return None

        logger.error("âŒ æ‰€æœ‰é‡è¯•å°è¯•å‡å¤±è´¥")
        return None
