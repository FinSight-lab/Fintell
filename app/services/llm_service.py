"""LLM Service - åŸºäº Gemini API çš„åˆ†ææœåŠ¡"""

import requests
import json
import logging
from typing import Dict, Any, Optional

logger = logging.getLogger(__name__)


class LLMService:
    """LLM æœåŠ¡ç±» - è°ƒç”¨ Gemini API ç”Ÿæˆå‘¨æŠ¥åˆ†æ"""

    def __init__(self, api_url: str, api_key: str, model: str = "gemini-3-pro-preview-thinking"):
        """
        åˆå§‹åŒ– LLM æœåŠ¡

        Args:
            api_url: API åœ°å€
            api_key: API å¯†é’¥
            model: æ¨¡å‹åç§°
        """
        self.api_url = api_url
        self.api_key = api_key
        self.model = model
    
    def generate_weekly_analysis(
        self, 
        report_data: Dict[str, Any],
        stream_callback=None
    ) -> Optional[Dict[str, Any]]:
        """
        ç”Ÿæˆå‘¨æŠ¥åˆ†æå†…å®¹
        
        Args:
            report_data: å‘¨æŠ¥æ•°æ®ï¼ˆåŒ…å«æŒä»“ã€è¡Œæƒ…ã€æŠ€æœ¯æŒ‡æ ‡ç­‰ï¼‰
            stream_callback: æµå¼è¾“å‡ºå›è°ƒå‡½æ•°ï¼Œæ¥æ”¶æ¯ä¸ªtoken
            
        Returns:
            Dict åŒ…å«:
                - core_viewpoint: æ ¸å¿ƒè§‚ç‚¹
                - holdings_analysis: æŒä»“ç›ˆäºåˆ†æ
                - stock_analysis: ä¸ªè‚¡åˆ†æåˆ—è¡¨
                - action_plan: è°ƒä»“å»ºè®®
                - risk_assessment: é£é™©è¯„ä¼°
                - sector_view: æ¿å—è§†è§’
        """
        try:
            # æ„å»ºç³»ç»Ÿæç¤ºè¯
            system_prompt = self._build_system_prompt()

            # æ„å»ºç”¨æˆ·è¾“å…¥
            user_prompt = self._build_user_prompt(report_data)
            
            # è°ƒç”¨ API
            response = self._call_api(system_prompt, user_prompt, stream_callback=stream_callback)
            
            if response:
                logger.info("âœ“ LLM åˆ†æå†…å®¹ç”ŸæˆæˆåŠŸ")
                return response
            else:
                logger.error("âœ— LLM è¿”å›ç©ºç»“æœ")
                return None
                
        except Exception as e:
            logger.error(f"ç”Ÿæˆåˆ†æå†…å®¹å¤±è´¥: {e}", exc_info=True)
            return None
        
    def _build_system_prompt(self) -> str:
        """æ„å»ºç³»ç»Ÿæç¤ºè¯"""
        return """# Role: ä¸“ä¸šè‚¡ç¥¨æŠ•èµ„åˆ†æå¸ˆ

ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è‚¡ç¥¨æŠ•èµ„åˆ†æå¸ˆï¼Œæ“…é•¿ A è‚¡å¸‚åœºåˆ†æå’ŒæŒä»“ç®¡ç†ï¼Œèƒ½å¤Ÿæ’°å†™**ç²¾ç®€ä½†ä¸“ä¸šã€é€»è¾‘æ¸…æ™°**çš„å‘¨æŠ¥åˆ†æã€‚

## Goals
åŸºäºæä¾›çš„æŒä»“æ•°æ®ã€è¡Œæƒ…æ•°æ®å’ŒæŠ€æœ¯æŒ‡æ ‡ï¼Œæç‚¼æœ¬å‘¨**æ ¸å¿ƒçŸ›ç›¾å’Œé©±åŠ¨å› ç´ **ï¼Œæ’°å†™ä¸€ç¯‡ç»“æ„åŒ–çš„å‘¨æŠ¥åˆ†æï¼Œç”¨äºå¡«å…… HTML å‘¨æŠ¥æ¨¡æ¿ã€‚

## æ€»ä½“å†™ä½œåŸåˆ™
1. **å…ˆæ‰¾ä¸»çº¿ï¼Œå†å†™ç»“æ„**  
   - ä»æ‰€æœ‰æ•°æ®ä¸­æŒ‘å‡º 2-3 ä¸ªå¯¹ç»„åˆæœ€å…³é”®çš„å˜åŒ–ï¼ˆå¦‚ï¼šæŸè‚¡ç¥¨æ˜æ˜¾èµ°å¼±ã€æŠ€æœ¯æŒ‡æ ‡åè½¬ã€ä»“ä½è¿‡äºé›†ä¸­ç­‰ï¼‰
   - ç« èŠ‚ç»“æ„å›´ç»•ä¸»çº¿ç»„ç»‡

2. **æ¯ä¸€èŠ‚éƒ½è¦æœ‰å®Œæ•´é€»è¾‘é“¾**  
   - "å‘ç”Ÿäº†ä»€ä¹ˆï¼Ÿ"â€”â€”ç”¨å…³é”®æ•°æ®ç‚¹æ¦‚æ‹¬
   - "ä¸ºä»€ä¹ˆï¼Ÿ"â€”â€”ä»æŠ€æœ¯é¢/åŸºæœ¬é¢/é¢˜æé€»è¾‘ç»™å‡ºè§£é‡Š
   - "å½±å“æ˜¯ä»€ä¹ˆï¼Ÿ"â€”â€”å¯¹æŒä»“ã€é£é™©ã€æ“ä½œæœ‰ä»€ä¹ˆå«ä¹‰

3. **ä¼˜å…ˆè¡Œä¸šé€»è¾‘ï¼Œè€Œä¸æ˜¯å †æ•°å­—**  
   - é¿å…æµæ°´è´¦å¼çš„æ•°æ®ç½—åˆ—
   - ä½¿ç”¨"å—Ã—Ã—é©±åŠ¨""åæ˜ å‡ºÃ—Ã—""å¯¼è‡´Ã—Ã—"ç­‰é€»è¾‘è¡”æ¥è¯

## æ•°æ®è§£è¯»çº¦æŸ

1. **æŠ€æœ¯æŒ‡æ ‡è§£è¯»**
   - MAï¼ˆå‡çº¿ï¼‰ï¼šå…³æ³¨ä»·æ ¼ä¸å‡çº¿çš„ä½ç½®å…³ç³»ã€å‡çº¿æ’åˆ—
   - RSIï¼šè¶…ä¹°ï¼ˆ>70ï¼‰ã€è¶…å–ï¼ˆ<30ï¼‰ã€ä¸­æ€§åŒºé—´
   - MACDï¼šé‡‘å‰/æ­»å‰ã€DIF/DEA ä½ç½®å…³ç³»
   - BOLLï¼šä»·æ ¼çªç ´ä¸Šè½¨/ä¸‹è½¨ã€å¸ƒæ—å¸¦æ”¶å£/å¼€å£

2. **A è‚¡ç‰¹è‰²åˆ†æ**
   - é¢˜æé€»è¾‘ï¼šå½“å‰å¸‚åœºä¸»çº¿ã€æ¿å—è½®åŠ¨ã€èµ„é‡‘åå¥½
   - é£æ ¼åˆ¤æ–­ï¼šæˆé•¿/ä»·å€¼/é«˜è‚¡æ¯/æ¶ˆè´¹ç­‰
   - æƒ…ç»ªåˆ¤æ–­ï¼šè¶…è·Œåå¼¹ã€è¿½æ¶¨æ€è·Œã€ææ…Œæ€§ä¸‹è·Œç­‰

3. **æ“ä½œå»ºè®®åŸåˆ™**
   - å…·ä½“å¯æ‰§è¡Œï¼šç»™å‡ºä»·æ ¼åŒºé—´ã€åˆ†æ‰¹è®¡åˆ’
   - é£é™©å¯æ§ï¼šæ­¢æŸä½ã€æ­¢ç›ˆä½
   - ç¬¦åˆ A è‚¡ä¹ æƒ¯ï¼šT+1ã€æ¶¨è·Œåœé™åˆ¶

## JSON è¾“å‡ºç»“æ„
{
  "core_viewpoint": "æ ¸å¿ƒè§‚ç‚¹æ–‡æœ¬ï¼ˆ80-120å­—ï¼Œå¯åŒ…å« <span class='highlight'>é«˜äº®</span>ï¼‰",
  "kpis": {
    "weekly_return": 0.0,  // æœ¬å‘¨æ”¶ç›Šç‡ï¼ˆ%ï¼‰
    "ytd_return": 0.0,     // å¹´åˆè‡³ä»Šæ”¶ç›Šç‡ï¼ˆ%ï¼‰
    "position_ratio": 0.0, // ä»“ä½å æ¯”ï¼ˆ%ï¼‰
    "action_count": 0      // å»ºè®®è°ƒä»“æ•°é‡
  },
  "holdings_analysis": {
    "summary": "æŒä»“ç›ˆäºæ€»ç»“ï¼ˆ100-150å­—ï¼‰",
    "highlights": ["è¦ç‚¹1", "è¦ç‚¹2", "è¦ç‚¹3"]
  },
  "stock_analysis": [
    {
      "stock_code": "600519.SH",
      "stock_name": "è´µå·èŒ…å°",
      "status": "è¶…å–åå¼¹/æ¨ªç›˜éœ‡è¡/è¶‹åŠ¿ç ´ä½/å¤šå¤´è¶‹åŠ¿/å›è°ƒé¢„è­¦",
      "status_class": "warning/neutral/negative/positive",
      "technical": "æŠ€æœ¯é¢åˆ†æï¼ˆ50-80å­—ï¼‰",
      "fundamental": "åŸºæœ¬é¢åˆ†æï¼ˆ50-80å­—ï¼‰",
      "theme": "é¢˜æé€»è¾‘åˆ†æï¼ˆ50-80å­—ï¼‰",
      "risk": "é£é™©ç‚¹ï¼ˆ30-50å­—ï¼‰",
      "suggestion": "æ“ä½œå»ºè®®ï¼ˆ50-80å­—ï¼ŒåŠ ç²—å…³é”®è¯ï¼‰"
    }
  ],
  "action_plan": [
    {
      "stock_code": "600519.SH",
      "stock_name": "è´µå·èŒ…å°",
      "action": "é€¢é«˜å‡ä»“/åå¼¹å‡ä»“/é€æ­¥æ¸…ä»“/ç»§ç»­æŒæœ‰/åŠ ä»“",
      "action_class": "reduce/clear/add/hold",
      "price_range": "1460-1480å…ƒ",
      "current_position": "45%",
      "target_position": "40%",
      "plan": "è§¦åŠåŒºé—´ä¸Šæ²¿åˆ†ä¸¤æ¬¡å„å‡2.5%",
      "reason": "å•ç¥¨ä»“ä½è¿‡é‡ï¼Œåˆ©ç”¨è¶…è·Œåå¼¹ä¼˜åŒ–é›†ä¸­åº¦"
    }
  ],
  "risk_assessment": {
    "level": "ä¸­ç­‰åé«˜/ä¸­ç­‰/åä½",
    "level_score": 65,  // 0-100
    "current_risks": [
      "è¡Œä¸šé›†ä¸­åº¦ï¼šè¿‘100%é›†ä¸­åœ¨æ³›æ¶ˆè´¹é¢†åŸŸ",
      "ä¸ªè‚¡é›†ä¸­åº¦ï¼šè´µå·èŒ…å°å•åªä»“ä½çº¦45%",
      "é£æ ¼å•ä¸€ï¼šé˜²å¾¡æ€§æ¶ˆè´¹å æ¯”é«˜ï¼Œè¿›æ”»æ€§ä¸è¶³"
    ],
    "optimization_suggestions": [
      "å»é‡å ï¼šå»ºè®®é€æ­¥å‡ä»“é£Ÿå“ETFå’Œæ¶ˆè´¹LOF",
      "æ­¢æŸå¼±åŠ¿ï¼šå¯¹ç€è±é›…ç­‰è¶‹åŠ¿ç ´ä½æ ‡çš„å‡ä»“",
      "å¢åŠ å¤šæ ·æ€§ï¼šé€‚åº¦é…ç½®ç§‘æŠ€æˆé•¿ã€é«˜è‚¡æ¯çº¢åˆ©"
    ]
  },
  "sector_view": {
    "summary": "ä»å½“å‰å¸‚åœºç»“æ„çœ‹ï¼Œæ¶ˆè´¹å¹¶éç»å¯¹ä¸»çº¿...",
    "main_theme": "ç§‘æŠ€æˆé•¿ï¼ˆå¦‚åŠå¯¼ä½“ã€ç®—åŠ›ï¼‰ã€é«˜è‚¡æ¯çº¢åˆ©",
    "consumer_position": "æ¶ˆè´¹å¤„äºæ·±è·Œåéœ‡è¡ä¿®å¤é˜¶æ®µ",
    "portfolio_position": "å½“å‰ç»„åˆæ›´æ¥è¿‘'è¿›å¯æ”»èƒ½åŠ›æœ‰é™ã€é€€å¯å®ˆå°šå¯'çš„çŠ¶æ€",
    "adjustment_direction": "é‡Šæ”¾éƒ¨åˆ†æ¶ˆè´¹ä»“ä½ï¼Œå¼•å…¥ç§‘æŠ€æˆé•¿ & é«˜è‚¡æ¯"
  },
  "target_allocation": {
    "consumer": 55,
    "tech_growth": 20,
    "dividend": 15,
    "cash": 10
  }
}

## Constraints
1. å¿…é¡»è¾“å‡º**ä¸¥æ ¼çš„ JSON æ ¼å¼**
2. `core_viewpoint` å­—æ•° 80-120 å­—
3. ä¸ªè‚¡åˆ†æè¦å…¨é¢è¦†ç›–æ‰€æœ‰æŒä»“
4. æ“ä½œå»ºè®®è¦å…·ä½“å¯æ‰§è¡Œ
5. é£é™©è¯„ä¼°è¦å®¢è§‚ä¸­è‚¯
6. è¯­è¨€é£æ ¼ï¼šä¸“ä¸šã€å®¢è§‚ã€æ•°æ®é©±åŠ¨
"""
    
    def _build_user_prompt(self, report_data: Dict[str, Any]) -> str:
        """æ„å»ºç”¨æˆ·æç¤ºè¯"""
        # æå–å…³é”®æ•°æ®
        portfolio = report_data.get('portfolio', {})
        metrics = report_data.get('metrics', {})
        holdings = report_data.get('holdings', [])
        period = report_data.get('period', '')
        
        # æ„å»ºæŒä»“æ•°æ®æ‘˜è¦
        holdings_summary = []
        for h in holdings:
            holdings_summary.append({
                "è‚¡ç¥¨ä»£ç ": h['stock_code'],
                "è‚¡ç¥¨åç§°": h['stock_name'],
                "å½“å‰ä»·æ ¼": f"{h['current_price']:.2f}",
                "æˆæœ¬ä»·": f"{h['cost_price']:.2f}",
                "æŒä»“æ•°é‡": h['quantity'],
                "å¸‚å€¼": f"{h['market_value']:.2f}",
                "ç›ˆäº": f"{h['profit_loss']:+.2f}",
                "ç›ˆäºæ¯”ä¾‹": f"{h['profit_loss_pct']:+.2f}%",
                "ä»“ä½å æ¯”": f"{h.get('position_ratio', 0):.1f}%",
                "æŠ€æœ¯æŒ‡æ ‡": h.get('indicators', {})
            })
        
        prompt = f"""è¯·åŸºäºä»¥ä¸‹æŒä»“æ•°æ®å’Œå¸‚åœºè¡Œæƒ…ï¼Œæ’°å†™ä¸€ç¯‡å‘¨æŠ¥åˆ†æã€‚

**ç»Ÿè®¡å‘¨æœŸ**ï¼š{period}

**ç»„åˆä¿¡æ¯**ï¼š
- ç»„åˆåç§°ï¼š{portfolio.get('name')}
- æ€»èµ„äº§ï¼šÂ¥{metrics.get('total_market_value', 0) + metrics.get('cash', 0):,.2f}
- æŒä»“å¸‚å€¼ï¼šÂ¥{metrics.get('total_market_value', 0):,.2f}
- ç°é‡‘ï¼šÂ¥{metrics.get('cash', 0):,.2f}
- ä»“ä½å æ¯”ï¼š{metrics.get('position_ratio', 0):.1f}%

**ç›ˆäºæƒ…å†µ**ï¼š
- æ€»ç›ˆäºï¼šÂ¥{metrics.get('total_profit_loss', 0):+,.2f}
- æ”¶ç›Šç‡ï¼š{metrics.get('total_return_pct', 0):+.2f}%

**æŒä»“æ˜ç»†**ï¼ˆ{len(holdings)} åªè‚¡ç¥¨ï¼‰ï¼š
{json.dumps(holdings_summary, ensure_ascii=False, indent=2)}

**è¦æ±‚**ï¼š
1. åˆ†ææ¯åªè‚¡ç¥¨çš„æŠ€æœ¯é¢ã€åŸºæœ¬é¢ã€é¢˜æé€»è¾‘
2. ç»™å‡ºå…·ä½“çš„æ“ä½œå»ºè®®ï¼ˆä»·æ ¼åŒºé—´ã€åˆ†æ‰¹è®¡åˆ’ï¼‰
3. è¯„ä¼°ç»„åˆé£é™©å¹¶æå‡ºä¼˜åŒ–å»ºè®®
4. åˆ†æå½“å‰å¸‚åœºä¸»çº¿å’Œæ¿å—è½®åŠ¨
5. è¾“å‡ºä¸¥æ ¼çš„ JSON æ ¼å¼

è¯·å¼€å§‹åˆ†æï¼š"""

        return prompt
    
    def _call_api(
        self, 
        system_prompt: str, 
        user_prompt: str, 
        max_retries: int = 3,
        stream_callback=None
    ) -> Optional[Dict[str, Any]]:
        """
        è°ƒç”¨ Gemini APIï¼ˆæµå¼è¾“å‡ºï¼Œå¸¦é‡è¯•æœºåˆ¶ï¼‰

        Args:
            system_prompt: ç³»ç»Ÿæç¤ºè¯
            user_prompt: ç”¨æˆ·æç¤ºè¯
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            stream_callback: æµå¼è¾“å‡ºå›è°ƒå‡½æ•°

        Returns:
            è§£æåçš„ JSON å“åº”
        """
        import time
        
        headers = {
            'Authorization': f'Bearer {self.api_key}',
            'Content-Type': 'application/json'
        }

        payload = {
            "model": self.model,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            "stream": True,
            "max_tokens": 50000,
            "temperature": 0.85,
            "top_p": 0.9,
            "top_k": 50,
            "frequency_penalty": 0.3,
            "response_format": {"type": "json_object"}
        }

        for attempt in range(max_retries):
            try:
                if attempt > 0:
                    wait_time = 2 ** attempt
                    logger.info(f"â³ ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    time.sleep(wait_time)
                
                logger.info(f"ğŸ¤– æ­£åœ¨è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆåˆ†æå†…å®¹... (å°è¯• {attempt + 1}/{max_retries})")
                response = requests.post(
                    self.api_url,
                    headers=headers,
                    json=payload,
                    stream=True,
                    timeout=300
                )
                response.raise_for_status()

                # æ”¶é›†æµå¼è¾“å‡º
                full_content = ""
                chunk_count = 0
                last_log_length = 0

                for line in response.iter_lines():
                    if not line:
                        continue

                    line = line.decode('utf-8')

                    if not line.startswith('data: '):
                        continue

                    data_str = line[6:]

                    if data_str.strip() == '[DONE]':
                        logger.info("âœ“ å¤§æ¨¡å‹å†…å®¹ç”Ÿæˆå®Œæˆ")
                        break

                    try:
                        data = json.loads(data_str)
                        delta = data.get('choices', [{}])[0].get('delta', {})
                        content_chunk = delta.get('content', '')

                        if content_chunk:
                            full_content += content_chunk
                            chunk_count += 1

                            if stream_callback:
                                stream_callback(content_chunk, len(full_content))

                            current_length = len(full_content)
                            if current_length - last_log_length >= 100:
                                logger.info(f"ğŸ“ å¤§æ¨¡å‹æ­£åœ¨å·¥ä½œä¸­ï¼Œå·²ç”Ÿæˆ {current_length} å­—...")
                                last_log_length = current_length

                    except json.JSONDecodeError:
                        continue

                logger.info(f"âœ“ å¤§æ¨¡å‹è¾“å‡ºå®Œæˆï¼Œå…±ç”Ÿæˆ {len(full_content)} å­—")

                if full_content:
                    # ä¿å­˜åŸå§‹å†…å®¹ç”¨äºè°ƒè¯•
                    original_content = full_content
                    
                    # 1. è¿‡æ»¤æ‰ <think> æ ‡ç­¾å†…å®¹ï¼ˆGemini çš„æ€è€ƒè¿‡ç¨‹ï¼‰
                    if '<think>' in full_content:
                        think_end = full_content.find('</think>')
                        if think_end != -1:
                            full_content = full_content[think_end + 8:].strip()
                            logger.info(f"âœ“ å·²è¿‡æ»¤æ€è€ƒå†…å®¹ï¼Œå‰©ä½™ {len(full_content)} å­—")
                    
                    # 2. å°è¯•æå– JSONï¼ˆå¯èƒ½åœ¨ markdown ä»£ç å—ä¸­ï¼‰
                    if '```json' in full_content:
                        start = full_content.find('```json') + 7
                        end = full_content.find('```', start)
                        if end != -1:
                            full_content = full_content[start:end].strip()
                            logger.info("âœ“ ä» markdown ä»£ç å—ä¸­æå– JSON")
                    elif '```' in full_content:
                        start = full_content.find('```') + 3
                        end = full_content.find('```', start)
                        if end != -1:
                            full_content = full_content[start:end].strip()
                            logger.info("âœ“ ä»ä»£ç å—ä¸­æå–å†…å®¹")
                    
                    # 3. å°è¯•æ‰¾åˆ° JSON å¯¹è±¡çš„å¼€å§‹å’Œç»“æŸ
                    if not full_content.strip().startswith('{'):
                        # æŸ¥æ‰¾ç¬¬ä¸€ä¸ª {
                        json_start = full_content.find('{')
                        if json_start != -1:
                            full_content = full_content[json_start:]
                            logger.info("âœ“ æ‰¾åˆ° JSON èµ·å§‹ä½ç½®")
                    
                    # 4. ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå– JSON
                    import re
                    
                    # å°è¯•ç›´æ¥è§£æ
                    try:
                        parsed_content = json.loads(full_content)
                        logger.info("âœ“ JSON è§£ææˆåŠŸï¼Œåˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ")
                        return parsed_content
                    except json.JSONDecodeError:
                        logger.warning("âš ï¸ ç›´æ¥è§£æå¤±è´¥ï¼Œå°è¯•ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå– JSON...")
                        
                        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æŸ¥æ‰¾ JSON å¯¹è±¡
                        # åŒ¹é…æœ€å¤–å±‚çš„ { ... }
                        json_pattern = r'\{(?:[^{}]|(?:\{(?:[^{}]|(?:\{[^{}]*\}))*\}))*\}'
                        matches = re.findall(json_pattern, full_content, re.DOTALL)
                        
                        if matches:
                            # å°è¯•è§£ææ‰¾åˆ°çš„æ¯ä¸ª JSON å¯¹è±¡
                            for i, match in enumerate(matches):
                                try:
                                    parsed_content = json.loads(match)
                                    # éªŒè¯æ˜¯å¦åŒ…å«å¿…è¦çš„å­—æ®µ
                                    if 'core_viewpoint' in parsed_content or 'stock_analysis' in parsed_content:
                                        logger.info(f"âœ“ ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æˆåŠŸæå–å¹¶è§£æ JSON (åŒ¹é… {i+1}/{len(matches)})")
                                        return parsed_content
                                except json.JSONDecodeError:
                                    continue
                        
                        logger.error("âœ— æ‰€æœ‰ JSON æå–å°è¯•å‡å¤±è´¥")
                        logger.error(f"å¤„ç†åå†…å®¹å‰500å­—: {full_content[:500]}...")
                        
                        # ä¿å­˜åŸå§‹å†…å®¹ç”¨äºè°ƒè¯•
                        with open("llm_error_output.txt", 'w', encoding='utf-8') as f:
                            f.write(original_content)
                        logger.error(f"åŸå§‹å†…å®¹å·²ä¿å­˜åˆ°: llm_error_output.txt")
                        
                        return None
                else:
                    logger.error("âœ— API è¿”å›å†…å®¹ä¸ºç©º")
                    return None

            except requests.exceptions.HTTPError as e:
                if e.response.status_code in [503, 502, 504, 429]:
                    logger.warning(f"âš ï¸ API æš‚æ—¶ä¸å¯ç”¨ ({e.response.status_code})ï¼Œå°†é‡è¯•...")
                    if attempt == max_retries - 1:
                        logger.error(f"âŒ å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œæ”¾å¼ƒè¯·æ±‚")
                        return None
                    continue
                else:
                    logger.error(f"API è¯·æ±‚å¤±è´¥: {e}")
                    return None
            except requests.exceptions.RequestException as e:
                logger.error(f"API è¯·æ±‚å¤±è´¥: {e}")
                if attempt == max_retries - 1:
                    return None
                continue
            except Exception as e:
                logger.error(f"å¤„ç†æµå¼è¾“å‡ºæ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
                return None
        
        logger.error("âŒ æ‰€æœ‰é‡è¯•å°è¯•å‡å¤±è´¥")
        return None
