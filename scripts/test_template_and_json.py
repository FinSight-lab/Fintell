"""
æµ‹è¯•æ–°çš„ Jinja2 æ¨¡æ¿å’Œ JSON æ­£åˆ™æå–åŠŸèƒ½
"""

import sys
import os
sys.path.insert(0, os.path.abspath('.'))

import json
import logging
from app.services.template_service import TemplateService

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)


def test_template_rendering():
    """æµ‹è¯•æ¨¡æ¿æ¸²æŸ“"""
    logger.info("=" * 60)
    logger.info("æµ‹è¯• 1: æ¨¡æ¿æ¸²æŸ“")
    logger.info("=" * 60)
    
    # åŠ è½½æµ‹è¯•æ•°æ®
    with open('test_data_output.json', 'r', encoding='utf-8') as f:
        test_data = json.load(f)
    
    # åˆ›å»ºæ¨¡æ‹Ÿçš„ LLM åˆ†æç»“æœ
    mock_analysis = {
        "core_viewpoint": "å½“å‰ç»„åˆå‘ˆç°å…¸å‹çš„<span class='highlight'>é˜²å¾¡æ€§æ¶ˆè´¹é…ç½®</span>ï¼Œä½†åœ¨æ¶ˆè´¹å¤è‹ä¹åŠ›çš„èƒŒæ™¯ä¸‹ï¼Œè¿›æ”»æ€§ä¸è¶³ã€‚",
        "kpis": {
            "weekly_return": -0.42,
            "ytd_return": test_data['metrics']['total_return_pct'],
            "position_ratio": test_data['metrics']['position_ratio'],
            "action_count": 3,
            "benchmark_return": -0.35,
            "ytd_comment": "æ³¢åŠ¨å¯æ§",
            "position_comment": "åé«˜ï¼ˆå»ºè®® 70%â€“80%ï¼‰",
            "action_summary": "æ ¸å¿ƒï¼šå»å¼±ç•™å¼ºã€å»é‡å "
        },
        "holdings_analysis": {
            "summary": "æœ¬å‘¨ç»„åˆå°å¹…å›æ’¤ï¼Œæ•´ä½“æ³¢åŠ¨ä»ä¸»è¦ç”±è´µå·èŒ…å°é©±åŠ¨ã€‚",
            "highlights": [
                "æœ¬å‘¨ç»„åˆå°å¹…å›æ’¤ï¼Œæ•´ä½“æ³¢åŠ¨ä»ä¸»è¦ç”±è´µå·èŒ…å°é©±åŠ¨ã€‚",
                "æ¶ˆè´¹ä¸ªè‚¡ + è¡Œä¸š ETF é«˜åº¦é‡å ï¼Œèµ„é‡‘åˆ©ç”¨æ•ˆç‡åä½ã€‚",
                "ç¼ºä¹ç§‘æŠ€æˆé•¿æˆ–é«˜è‚¡æ¯ç­‰é£æ ¼é…ç½®ï¼Œå¯¹å•ä¸€è¡Œä¸šè¿‡åº¦æš´éœ²ã€‚"
            ]
        },
        "stock_analysis": [
            {
                "stock_code": "600519.SH",
                "stock_name": "è´µå·èŒ…å°",
                "status": "è¶…å–åå¼¹",
                "status_class": "warning",
                "technical": "å‡çº¿ç©ºå¤´æ’åˆ—ï¼Œä½† RSI(6) è·Œè‡³ 43.6ï¼ŒçŸ­æœŸå­˜åœ¨æŠ€æœ¯åå¼¹éœ€æ±‚ã€‚",
                "fundamental": "ç°é‡‘æµç¨³å¥ã€å“ç‰ŒåŠ›æå¼ºï¼Œé•¿æœŸé€»è¾‘æœªæ”¹å˜ã€‚",
                "theme": "å±äºç™½é…’æ¿å—æ ¸å¿ƒèµ„äº§ï¼Œå½“å‰ä¸åœ¨ A è‚¡ä¸»çº¿ä¸­ã€‚",
                "risk": "ä¼°å€¼ä»å¤„é«˜ä½ï¼Œä¸€æ—¦æ¶ˆè´¹æ¢å¤ä¸åŠé¢„æœŸï¼Œå¯èƒ½é¢ä¸´ä¼°å€¼ä¸­æ¢ä¸‹ç§»é£é™©ã€‚",
                "suggestion": "<strong>æŒæœ‰ä¸ºä¸»ï¼Œé€¢é«˜å‡ä»“</strong>ã€‚åå¼¹è‡³ 1460â€“1480 åŒºé—´å¯è€ƒè™‘å‡ä»“ 5% å·¦å³ã€‚"
            }
        ],
        "action_plan": [
            {
                "stock_code": "600519.SH",
                "stock_name": "è´µå·èŒ…å°",
                "action": "é€¢é«˜å‡ä»“",
                "action_class": "reduce",
                "price_range": "1460-1480å…ƒ",
                "current_position": "34.4%",
                "target_position": "30%",
                "plan": "è§¦åŠåŒºé—´ä¸Šæ²¿åˆ†ä¸¤æ¬¡å„å‡2.5%",
                "reason": "å•ç¥¨ä»“ä½è¿‡é‡ï¼Œåˆ©ç”¨è¶…è·Œåå¼¹ä¼˜åŒ–é›†ä¸­åº¦"
            }
        ],
        "risk_assessment": {
            "level": "ä¸­ç­‰åé«˜",
            "level_score": 65,
            "current_risks": [
                "<strong>è¡Œä¸šé›†ä¸­åº¦ï¼š</strong><span class='text-down'>è¿‘ 100% é›†ä¸­åœ¨æ³›æ¶ˆè´¹é¢†åŸŸ</span>",
                "<strong>ä¸ªè‚¡é›†ä¸­åº¦ï¼š</strong>è´µå·èŒ…å°å•åªä»“ä½çº¦ <span class='text-down'>34%</span>"
            ],
            "optimization_suggestions": [
                "<strong>å»é‡å ï¼š</strong>å»ºè®®é€æ­¥å‡ä»“é£Ÿå“ETFå’Œæ¶ˆè´¹LOF",
                "<strong>æ­¢æŸå¼±åŠ¿ï¼š</strong>å¯¹ç€è±é›…ç­‰è¶‹åŠ¿ç ´ä½æ ‡çš„å‡ä»“"
            ]
        },
        "sector_view": {
            "summary": "ä»å½“å‰å¸‚åœºç»“æ„çœ‹ï¼Œæ¶ˆè´¹å¹¶éç»å¯¹ä¸»çº¿ï¼Œæ›´åå‘äº"é˜²å¾¡+ä¿®å¤"æ–¹å‘ã€‚",
            "main_theme": "ç§‘æŠ€æˆé•¿ï¼ˆå¦‚åŠå¯¼ä½“ã€ç®—åŠ›ï¼‰ã€é«˜è‚¡æ¯çº¢åˆ©",
            "consumer_position": "æ¶ˆè´¹å¤„äºæ·±è·Œåéœ‡è¡ä¿®å¤é˜¶æ®µ",
            "portfolio_position": "å½“å‰ç»„åˆæ›´æ¥è¿‘'è¿›å¯æ”»èƒ½åŠ›æœ‰é™ã€é€€å¯å®ˆå°šå¯'çš„çŠ¶æ€",
            "adjustment_direction": "é‡Šæ”¾éƒ¨åˆ†æ¶ˆè´¹ä»“ä½ï¼Œå¼•å…¥ç§‘æŠ€æˆé•¿ & é«˜è‚¡æ¯"
        },
        "target_allocation": {
            "consumer": 55,
            "tech_growth": 20,
            "dividend": 15,
            "cash": 10
        }
    }
    
    # å‡†å¤‡æ¨¡æ¿æ•°æ®
    template_data = {
        "period": test_data['period'],
        "report_date": test_data['report_date'],
        "portfolio": test_data['portfolio'],
        "metrics": test_data['metrics'],
        "holdings": test_data['holdings'],
        "analysis": mock_analysis
    }
    
    # æ¸²æŸ“æ¨¡æ¿
    template_service = TemplateService()
    html = template_service.render_weekly_report(template_data)
    
    if html:
        # ä¿å­˜ HTML
        output_path = "output/test_weekly_report.html"
        if template_service.save_html(html, output_path):
            logger.info(f"âœ“ æµ‹è¯•æˆåŠŸï¼HTML å·²ä¿å­˜åˆ°: {output_path}")
            logger.info(f"  HTML é•¿åº¦: {len(html)} å­—ç¬¦")
            return True
        else:
            logger.error("âœ— ä¿å­˜ HTML å¤±è´¥")
            return False
    else:
        logger.error("âœ— æ¨¡æ¿æ¸²æŸ“å¤±è´¥")
        return False


def test_json_extraction():
    """æµ‹è¯• JSON æ­£åˆ™æå–"""
    logger.info("\n" + "=" * 60)
    logger.info("æµ‹è¯• 2: JSON æ­£åˆ™æå–")
    logger.info("=" * 60)
    
    import re
    
    # æ¨¡æ‹Ÿå„ç§ LLM è¾“å‡ºæ ¼å¼
    test_cases = [
        {
            "name": "æ ‡å‡† JSON",
            "content": '{"core_viewpoint": "æµ‹è¯•å†…å®¹", "kpis": {"weekly_return": 1.5}}'
        },
        {
            "name": "å¸¦ markdown ä»£ç å—",
            "content": '```json\n{"core_viewpoint": "æµ‹è¯•å†…å®¹", "kpis": {"weekly_return": 1.5}}\n```'
        },
        {
            "name": "å¸¦å‰ç¼€æ–‡æœ¬",
            "content": 'è¿™æ˜¯åˆ†æç»“æœï¼š\n{"core_viewpoint": "æµ‹è¯•å†…å®¹", "kpis": {"weekly_return": 1.5}}'
        },
        {
            "name": "å¸¦ <think> æ ‡ç­¾",
            "content": '<think>æ€è€ƒè¿‡ç¨‹...</think>\n{"core_viewpoint": "æµ‹è¯•å†…å®¹", "kpis": {"weekly_return": 1.5}}'
        },
        {
            "name": "åµŒå¥— JSON",
            "content": 'å¤–å±‚æ–‡æœ¬ {"core_viewpoint": "æµ‹è¯•", "nested": {"data": {"value": 123}}} åç»­æ–‡æœ¬'
        }
    ]
    
    success_count = 0
    
    for i, test_case in enumerate(test_cases, 1):
        logger.info(f"\næµ‹è¯•ç”¨ä¾‹ {i}: {test_case['name']}")
        logger.info(f"åŸå§‹å†…å®¹: {test_case['content'][:100]}...")
        
        content = test_case['content']
        
        # 1. è¿‡æ»¤ <think> æ ‡ç­¾
        if '<think>' in content:
            think_end = content.find('</think>')
            if think_end != -1:
                content = content[think_end + 8:].strip()
                logger.info("  âœ“ å·²è¿‡æ»¤ <think> æ ‡ç­¾")
        
        # 2. æå– markdown ä»£ç å—
        if '```json' in content:
            start = content.find('```json') + 7
            end = content.find('```', start)
            if end != -1:
                content = content[start:end].strip()
                logger.info("  âœ“ ä» markdown ä»£ç å—ä¸­æå–")
        elif '```' in content:
            start = content.find('```') + 3
            end = content.find('```', start)
            if end != -1:
                content = content[start:end].strip()
                logger.info("  âœ“ ä»ä»£ç å—ä¸­æå–")
        
        # 3. æŸ¥æ‰¾ JSON å¯¹è±¡
        if not content.strip().startswith('{'):
            json_start = content.find('{')
            if json_start != -1:
                content = content[json_start:]
                logger.info("  âœ“ æ‰¾åˆ° JSON èµ·å§‹ä½ç½®")
        
        # 4. å°è¯•è§£æ
        try:
            parsed = json.loads(content)
            logger.info(f"  âœ“ JSON è§£ææˆåŠŸ: {list(parsed.keys())}")
            success_count += 1
        except json.JSONDecodeError as e:
            logger.warning(f"  âœ— ç›´æ¥è§£æå¤±è´¥: {e}")
            
            # 5. ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–
            json_pattern = r'\{(?:[^{}]|(?:\{(?:[^{}]|(?:\{[^{}]*\}))*\}))*\}'
            matches = re.findall(json_pattern, content, re.DOTALL)
            
            if matches:
                logger.info(f"  æ‰¾åˆ° {len(matches)} ä¸ª JSON å¯¹è±¡")
                for j, match in enumerate(matches):
                    try:
                        parsed = json.loads(match)
                        if 'core_viewpoint' in parsed or 'kpis' in parsed:
                            logger.info(f"  âœ“ æ­£åˆ™æå–æˆåŠŸ (åŒ¹é… {j+1}): {list(parsed.keys())}")
                            success_count += 1
                            break
                    except json.JSONDecodeError:
                        continue
            else:
                logger.error("  âœ— æ­£åˆ™æå–ä¹Ÿå¤±è´¥")
    
    logger.info(f"\næ€»ç»“: {success_count}/{len(test_cases)} ä¸ªæµ‹è¯•ç”¨ä¾‹æˆåŠŸ")
    return success_count == len(test_cases)


if __name__ == "__main__":
    logger.info("å¼€å§‹æµ‹è¯•æ–°æ¨¡æ¿å’Œ JSON æå–åŠŸèƒ½\n")
    
    # æµ‹è¯• 1: æ¨¡æ¿æ¸²æŸ“
    test1_passed = test_template_rendering()
    
    # æµ‹è¯• 2: JSON æå–
    test2_passed = test_json_extraction()
    
    # æ€»ç»“
    logger.info("\n" + "=" * 60)
    logger.info("æµ‹è¯•æ€»ç»“")
    logger.info("=" * 60)
    logger.info(f"æ¨¡æ¿æ¸²æŸ“: {'âœ“ é€šè¿‡' if test1_passed else 'âœ— å¤±è´¥'}")
    logger.info(f"JSON æå–: {'âœ“ é€šè¿‡' if test2_passed else 'âœ— å¤±è´¥'}")
    
    if test1_passed and test2_passed:
        logger.info("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        sys.exit(0)
    else:
        logger.error("\nâŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥")
        sys.exit(1)
